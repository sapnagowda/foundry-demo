{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸš€ Agent Framework to Foundry Agents: A Step-by-Step Walkthrough\n\n> **Author:** Ozgur Guler | AI Solution Leader, AI Innovation Hub\n> **Contact:** [ozgur.guler1@gmail.com](mailto:ozgur.guler1@gmail.com)\n> **Â© 2025 Ozgur Guler. All rights reserved.**\n\n---\n\nThis notebook guides you through the progression of building AI agents, from simple local agents to Azure AI Foundry managed agents.\n\n## What You'll Learn\n\n1. **Simple Agent Framework Agent** â€” Run an agent locally that calls Azure OpenAI\n2. **Agent Framework with Reasoning** â€” Add reasoning capabilities (o1/o3 models)\n3. **Foundry Agent Service (Classic)** â€” Create agents managed by Azure AI Foundry\n4. **Agent Framework + Foundry** â€” Best of both worlds: your code + Foundry's managed runtime\n\n## Prerequisites\n\n- Python 3.10+\n- Azure subscription with Azure OpenAI access\n- `.env` file configured (see `00-environment-setup/`)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Setup: Install Dependencies & Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q python-dotenv azure-identity azure-ai-agents\n",
    "%pip install -q agent-framework-core agent-framework-azure-ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "required_vars = [\"AZURE_OPENAI_ENDPOINT\", \"AZURE_OPENAI_DEPLOYMENT_NAME\", \"AZURE_OPENAI_API_VERSION\"]\n",
    "missing = [v for v in required_vars if not os.getenv(v)]\n",
    "if missing:\n",
    "    print(f\"âš ï¸ Missing: {missing}\")\n",
    "else:\n",
    "    print(\"âœ… Environment loaded!\")\n",
    "    print(f\"   Endpoint: {os.getenv('AZURE_OPENAI_ENDPOINT')[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1ï¸âƒ£ Simple Agent Framework Agent (`01-af-standard-agent.py`)\n",
    "\n",
    "### What This Does\n",
    "\n",
    "The **simplest possible agent**:\n",
    "- Runs **locally on your machine**\n",
    "- Calls Azure OpenAI's **Responses API** over HTTPS\n",
    "- Uses **Agent Framework** for a clean API\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         HTTPS          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Your Computer     â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶   â”‚  Azure OpenAI       â”‚\n",
    "â”‚   (Python script)   â”‚ â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚  (Model endpoint)   â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Explanation |\n",
    "|---------|-------------|\n",
    "| `AzureOpenAIResponsesClient` | Client that wraps Azure OpenAI Responses API |\n",
    "| `create_agent()` | Creates an agent with name and instructions |\n",
    "| `agent.run()` | Sends a message and gets a response |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01-af-standard-agent.py â€” Simple Agent Framework Agent\n",
    "# Agent runs LOCALLY, calls Azure OpenAI over HTTPS\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "\n",
    "async def run_simple_agent():\n",
    "    # Step 1: Create client that connects to Azure OpenAI\n",
    "    client = AzureOpenAIResponsesClient(\n",
    "        endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"],\n",
    "        api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "    \n",
    "    # Step 2: Create an \"agent\" with a persona (local Python object)\n",
    "    agent = client.create_agent(\n",
    "        name=\"physicsbot\",\n",
    "        instructions=\"You are a professor in astrophysics. Be concise.\",\n",
    "    )\n",
    "    \n",
    "    # Step 3: Run the agent (calls Azure OpenAI)\n",
    "    response = await agent.run(\"Are we in a black hole?\")\n",
    "    return response\n",
    "\n",
    "result = await run_simple_agent()\n",
    "print(\"ğŸ¤– Agent Response:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Start Here?\n",
    "\n",
    "This is the **baseline**:\n",
    "- âœ… Verify Azure OpenAI connection works\n",
    "- âœ… Understand the basic pattern (create â†’ configure â†’ run)\n",
    "- âœ… See that an \"agent\" is just code that calls an API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2ï¸âƒ£ Agent with Reasoning (`02-af-standard-agent-reasoning.py`)\n",
    "\n",
    "### What's Different?\n",
    "\n",
    "Uses a **reasoning model** (o1/o3) that \"thinks\" before responding.\n",
    "\n",
    "| Standard Agent | Reasoning Agent |\n",
    "|---------------|----------------|\n",
    "| GPT-4o | o1/o3 models |\n",
    "| Direct response | Thinks first |\n",
    "| Fast | Slower but more accurate |\n",
    "\n",
    "### Key Addition: `reasoning_effort`\n",
    "\n",
    "```python\n",
    "reasoning_effort=\"minimal\"  # or \"medium\" or \"high\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02-af-standard-agent-reasoning.py â€” Agent with Reasoning Model\n",
    "\n",
    "import os\n",
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "\n",
    "async def run_reasoning_agent():\n",
    "    reasoning_deployment = os.environ.get(\"AZURE_OPENAI_REASONING_DEPLOYMENT_NAME\")\n",
    "    if not reasoning_deployment:\n",
    "        print(\"âš ï¸ No reasoning model configured, using standard deployment\")\n",
    "        reasoning_deployment = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "    \n",
    "    client = AzureOpenAIResponsesClient(\n",
    "        endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        deployment_name=reasoning_deployment,\n",
    "        api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "    \n",
    "    # NEW: reasoning_effort parameter (only works with o1/o3 models)\n",
    "    agent = client.create_agent(\n",
    "        name=\"physicsbot\",\n",
    "        instructions=\"You are a professor in astrophysics.\",\n",
    "        reasoning_effort=\"minimal\",\n",
    "    )\n",
    "    \n",
    "    return await agent.run(\"Are we in a black hole? Explain your reasoning.\")\n",
    "\n",
    "try:\n",
    "    result = await run_reasoning_agent()\n",
    "    print(\"ğŸ§  Reasoning Agent:\")\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3ï¸âƒ£ Foundry Agent Service â€” Classic (`03-foundry-agent-basic.py`)\n",
    "\n",
    "### ğŸ”„ This is a Fundamental Shift!\n",
    "\n",
    "Instead of running the agent locally:\n",
    "- The **agent lives in Azure AI Foundry**\n",
    "- The **thread (conversation) lives in Foundry**\n",
    "- The **run (execution) happens in Foundry**\n",
    "\n",
    "Your code becomes a **client/orchestrator**.\n",
    "\n",
    "### Architecture Comparison\n",
    "\n",
    "```\n",
    "LOCAL (Steps 1-2):                       FOUNDRY (Step 3):\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Your Code           â”‚                 â”‚  Your Code           â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                 â”‚  (orchestrator only) â”‚\n",
    "â”‚  â”‚ Agent Logic    â”‚  â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "â”‚  â”‚ Thread/History â”‚  â”‚                            â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                            â–¼\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "           â–¼                             â”‚  Azure AI Foundry    â”‚\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  Azure OpenAI        â”‚                 â”‚  â”‚ Agent + Thread â”‚  â”‚\n",
    "â”‚  (Model only)        â”‚                 â”‚  â”‚ + Execution    â”‚  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "                                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "| Concept | Explanation |\n",
    "|---------|-------------|\n",
    "| `AgentsClient` | Client to talk to Foundry Agent Service |\n",
    "| `create_agent()` | Creates agent **in Foundry** (returns ID) |\n",
    "| `threads.create()` | Creates conversation **in Foundry** |\n",
    "| `runs.create_and_process()` | Executes agent **in Foundry** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03-foundry-agent-basic.py â€” Foundry Agent Service (Classic)\n",
    "# Agent runs IN FOUNDRY, not locally!\n",
    "\n",
    "import os\n",
    "from azure.ai.agents import AgentsClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.agents.models import CodeInterpreterTool\n",
    "\n",
    "def run_foundry_agent():\n",
    "    # Foundry PROJECT endpoint (not Azure OpenAI!)\n",
    "    # Format: https://<name>.services.ai.azure.com/api/projects/<project>\n",
    "    project_endpoint = os.getenv(\"PROJECT_ENDPOINT\") or os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "    model_deployment = os.getenv(\"MODEL_DEPLOYMENT_NAME\") or os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "    \n",
    "    if not project_endpoint:\n",
    "        raise ValueError(\"Missing PROJECT_ENDPOINT\")\n",
    "    \n",
    "    print(f\"ğŸ“ Foundry: {project_endpoint[:60]}...\")\n",
    "    \n",
    "    credential = DefaultAzureCredential()\n",
    "    agents_client = AgentsClient(endpoint=project_endpoint, credential=credential)\n",
    "    \n",
    "    with agents_client:\n",
    "        code_interpreter = CodeInterpreterTool()\n",
    "        \n",
    "        # Step 1: Create agent IN FOUNDRY\n",
    "        agent = agents_client.create_agent(\n",
    "            model=model_deployment,\n",
    "            name=\"Quickstart\",\n",
    "            instructions=\"Be concise.\",\n",
    "            tools=code_interpreter.definitions,\n",
    "            tool_resources=code_interpreter.resources,\n",
    "        )\n",
    "        print(f\"âœ… Created agent: {agent.id}\")\n",
    "        \n",
    "        # Step 2: Create thread IN FOUNDRY\n",
    "        thread = agents_client.threads.create()\n",
    "        print(f\"âœ… Created thread: {thread.id}\")\n",
    "        \n",
    "        # Step 3: Add message IN FOUNDRY\n",
    "        agents_client.messages.create(\n",
    "            thread_id=thread.id,\n",
    "            role=\"user\",\n",
    "            content=\"Write a haiku about Azure AI Foundry.\",\n",
    "        )\n",
    "        \n",
    "        # Step 4: Run agent IN FOUNDRY\n",
    "        run = agents_client.runs.create_and_process(\n",
    "            thread_id=thread.id,\n",
    "            agent_id=agent.id,\n",
    "        )\n",
    "        print(f\"âœ… Run status: {run.status}\")\n",
    "        \n",
    "        # Step 5: Fetch conversation FROM FOUNDRY\n",
    "        messages = agents_client.messages.list(thread_id=thread.id)\n",
    "        print(\"\\nğŸ“ Conversation:\")\n",
    "        for m in messages:\n",
    "            content = m.content[0].text.value if m.content else str(m.content)\n",
    "            print(f\"{'ğŸ§‘' if m.role == 'user' else 'ğŸ¤–'} {m.role}: {content}\")\n",
    "\n",
    "try:\n",
    "    run_foundry_agent()\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error: {e}\")\n",
    "    print(\"Make sure PROJECT_ENDPOINT is your Foundry project endpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Use Foundry Agent Service?\n",
    "\n",
    "| Benefit | Explanation |\n",
    "|---------|-------------|\n",
    "| **Managed runtime** | No infrastructure to manage |\n",
    "| **Built-in tools** | Code Interpreter, File Search |\n",
    "| **Thread persistence** | Conversations stored in Azure |\n",
    "| **Scalability** | Foundry handles scaling |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4ï¸âƒ£ Agent Framework + Foundry (`03-af-foundry-agent-basic.py`)\n",
    "\n",
    "### Best of Both Worlds\n",
    "\n",
    "- **Agent Framework**: Clean, simple API\n",
    "- **Foundry Agent Service**: Managed runtime\n",
    "\n",
    "### Code Comparison\n",
    "\n",
    "**Foundry Only (verbose):**\n",
    "```python\n",
    "agent = agents_client.create_agent(...)\n",
    "thread = agents_client.threads.create()\n",
    "agents_client.messages.create(thread_id=thread.id, ...)\n",
    "run = agents_client.runs.create_and_process(...)\n",
    "messages = agents_client.messages.list(...)\n",
    "```\n",
    "\n",
    "**Agent Framework + Foundry (clean):**\n",
    "```python\n",
    "async with AzureAIAgentClient(...).create_agent(...) as agent:\n",
    "    result = await agent.run(\"Your message\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 03-af-foundry-agent-basic.py â€” Agent Framework + Foundry\n",
    "# Clean API + Managed execution\n",
    "\n",
    "import os\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "from azure.ai.agents.aio import AgentsClient\n",
    "from agent_framework.azure import AzureAIAgentClient\n",
    "\n",
    "async def run_af_foundry_agent():\n",
    "    project_endpoint = os.getenv(\"PROJECT_ENDPOINT\") or os.getenv(\"AZURE_AI_PROJECT_ENDPOINT\")\n",
    "    model_deployment = os.getenv(\"MODEL_DEPLOYMENT_NAME\") or os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "    \n",
    "    if not project_endpoint:\n",
    "        raise ValueError(\"Missing PROJECT_ENDPOINT\")\n",
    "    \n",
    "    print(f\"ğŸ“ Foundry: {project_endpoint[:60]}...\")\n",
    "    \n",
    "    async with DefaultAzureCredential() as credential:\n",
    "        async with AgentsClient(endpoint=project_endpoint, credential=credential) as agents_client:\n",
    "            \n",
    "            # AzureAIAgentClient wraps Foundry with Agent Framework API\n",
    "            # should_cleanup_agent=True: delete agent when done\n",
    "            async with AzureAIAgentClient(\n",
    "                agents_client=agents_client,\n",
    "                model_deployment_name=model_deployment,\n",
    "                should_cleanup_agent=True,\n",
    "            ).create_agent(\n",
    "                name=\"Quickstart\",\n",
    "                instructions=\"Be concise.\",\n",
    "            ) as agent:\n",
    "                \n",
    "                # Looks like local Agent Framework, executes in Foundry!\n",
    "                result = await agent.run(\"Write a haiku about Azure AI Foundry.\")\n",
    "                print(\"ğŸ¤– Response:\")\n",
    "                print(result)\n",
    "\n",
    "try:\n",
    "    await run_af_foundry_agent()\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Summary: Choosing the Right Approach\n",
    "\n",
    "| Approach | File | Best For | Trade-offs |\n",
    "|----------|------|----------|------------|\n",
    "| **Local Agent Framework** | `01-af-standard-agent.py` | Prototyping, full control | You manage everything |\n",
    "| **Local + Reasoning** | `02-af-standard-agent-reasoning.py` | Complex reasoning tasks | Slower, requires o1/o3 |\n",
    "| **Foundry Classic** | `03-foundry-agent-basic.py` | Zero-ops, built-in tools | Verbose API |\n",
    "| **AF + Foundry** | `03-af-foundry-agent-basic.py` | Production with clean code | Best of both |\n",
    "\n",
    "## ğŸ¯ What's Next?\n",
    "\n",
    "**`02-azd-deploy-hosted-agent/`** â€” Containerized agents\n",
    "\n",
    "Hosted agents give you:\n",
    "- Your code in a container (full dependency control)\n",
    "- Foundry as the control plane (deploy/version/rollback)\n",
    "- Enterprise governance (Agent ID, Conditional Access)\n",
    "- MCP tool support via APIM"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n<div align=\"center\">\n\n## License & Attribution\n\nThis notebook is part of the **Azure AI Foundry Demo Repository**\n\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](../LICENSE)\n\n**Original Author:** Ozgur Guler | AI Solution Leader, AI Innovation Hub\n\n**Contact:** [ozgur.guler1@gmail.com](mailto:ozgur.guler1@gmail.com)\n\n---\n\n*If you use, modify, or distribute this work, you must provide appropriate credit to the original author as required by the [Apache License 2.0](../LICENSE).*\n\n**Copyright Â© 2025 Ozgur Guler. All rights reserved.**\n\n</div>",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}